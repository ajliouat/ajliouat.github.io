<!-- _includes/head.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Building a hierarchical VLM+RL manipulation system</title>
  <style>
    :root {
      --bg: #ffffff;
      --surface: #ffffff;
      --border: #e5e7eb;
      --text: #0f172a;
      --muted: #6b7280;
      --accent: #2563eb;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text", system-ui, -system-ui, sans-serif;
      background: radial-gradient(circle at top, #f9fafb 0, #ffffff 52%, #f3f4f6 100%);
      color: var(--text);
    }

    a {
      color: inherit;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .site-nav {
      position: sticky;
      top: 0;
      z-index: 20;
      border-bottom: 1px solid var(--border);
      background: rgba(255, 255, 255, 0.96);
      backdrop-filter: blur(12px);
    }

    .nav-inner {
      max-width: 960px;
      margin: 0 auto;
      padding: 0.9rem 1.5rem 0.7rem;
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 1.5rem;
    }

    .nav-brand {
      font-size: 14px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--muted);
    }

    .nav-links {
      display: flex;
      gap: 1.5rem;
      font-size: 13px;
      align-items: center;
    }

    .nav-link {
      text-decoration: none;
      color: var(--muted);
      padding: 6px 0;
      position: relative;
      transition: color 0.18s ease;
    }

    .nav-link::after {
      content: "";
      position: absolute;
      left: 0;
      right: 0;
      bottom: -4px;
      height: 1.5px;
      transform: scaleX(0);
      transform-origin: center;
      background: linear-gradient(to right, #1d4ed8, #0ea5e9);
      transition: transform 0.18s ease;
    }

    .nav-link:hover {
      color: var(--text);
    }

    .nav-link:hover::after {
      transform: scaleX(1);
    }

    .nav-link-active {
      color: var(--text);
      font-weight: 500;
    }

    .nav-link-active::after {
      transform: scaleX(1);
    }

    .page {
      max-width: 720px;
      margin: 0 auto;
      padding: 3.5rem 1.5rem 4rem;
    }

    .section-header {
      text-align: center;
      margin-bottom: 2.5rem;
    }

    .section-badge {
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
      padding: 0.15rem 0.75rem;
      border-radius: 999px;
      border: 1px solid rgba(37, 99, 235, 0.25);
      font-size: 11px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: #1d4ed8;
      background-color: #eff6ff;
    }

    .section-badge::before {
      content: "";
      width: 6px;
      height: 6px;
      border-radius: 999px;
      background: radial-gradient(circle at 30% 30%, #bfdbfe, #1d4ed8);
      box-shadow: 0 0 0 1px rgba(37, 99, 235, 0.45);
    }

    .section-title {
      margin-top: 1rem;
      font-size: 24px;
      font-weight: 500;
      letter-spacing: -0.02em;
    }

    .section-subtitle {
      max-width: 540px;
      margin: 0.75rem auto 0;
      font-size: 14px;
      line-height: 1.7;
      color: var(--muted);
    }

    .post-meta {
      margin-top: 1rem;
      font-size: 12px;
      color: var(--muted);
    }

    .toc {
      border-radius: 0.75rem;
      border: 1px solid var(--border);
      background-color: var(--surface);
      padding: 0.9rem 1rem;
      font-size: 13px;
      margin-top: 2.2rem;
    }

    .toc-title {
      font-size: 12px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--muted);
      margin: 0 0 0.5rem;
    }

    .toc ul {
      list-style: none;
      padding-left: 0;
      margin: 0;
    }

    .toc li + li {
      margin-top: 0.25rem;
    }

    .toc a {
      color: var(--accent);
      text-decoration: none;
      font-size: 13px;
    }

    .post-body {
      margin-top: 2.5rem;
      font-size: 14px;
      line-height: 1.8;
      color: var(--text);
    }

    .post-body p {
      margin: 0 0 1rem;
    }

    .post-body h2 {
      font-size: 16px;
      font-weight: 500;
      margin: 2rem 0 0.75rem;
      letter-spacing: -0.01em;
    }

    .post-body ul {
      margin: 0.5rem 0 1.5rem;
      padding-left: 1.1rem;
    }

    .post-body li {
      margin-bottom: 0.35rem;
    }

    .post-body table {
      width: 100%;
      border-collapse: collapse;
      margin: 1rem 0 1.5rem;
      font-size: 12px;
    }

    .post-body th, .post-body td {
      padding: 6px 10px;
      border: 1px solid var(--border);
      text-align: left;
    }

    .post-body th {
      background: rgba(148, 163, 184, 0.08);
      font-weight: 500;
      text-transform: uppercase;
      letter-spacing: 0.06em;
      font-size: 11px;
    }

    pre {
      margin: 1.5rem 0;
      padding: 0.9rem 1rem;
      border-radius: 0.6rem;
      background-color: #020617;
      color: #e5e7eb;
      font-size: 12px;
      line-height: 1.7;
      overflow-x: auto;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }

    code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
      font-size: 13px;
      padding: 1px 4px;
      border-radius: 4px;
      background: rgba(148, 163, 184, 0.1);
    }

    pre code {
      background: none;
      padding: 0;
    }

    .code-label {
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      color: var(--muted);
      margin-bottom: 0.25rem;
    }

    .mermaid-block {
      margin: 1.75rem 0;
      border-radius: 0.75rem;
      border: 1px dashed var(--border);
      background: var(--surface);
      padding: 0.9rem 1rem;
      overflow-x: auto;
    }

    .mermaid-block .code-label {
      margin-bottom: 0.4rem;
    }

    .mermaid {
      margin: 0;
    }

    .site-footer {
      border-top: 1px solid var(--border);
      margin-top: 3rem;
    }

    .site-footer-inner {
      max-width: 960px;
      margin: 0 auto;
      padding: 1.5rem 1.5rem 2.25rem;
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 1.5rem;
      font-size: 12px;
      color: var(--muted);
    }

    .site-footer-left {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .site-footer-brand {
      font-size: 12px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
    }

    .site-footer-right {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      font-size: 12px;
    }

    .site-footer-right a {
      color: var(--accent);
    }

    @media (max-width: 720px) {
      .nav-inner {
        padding-inline: 1rem;
      }

      .nav-links {
        gap: 1rem;
        font-size: 12px;
      }

      .page {
        padding-inline: 1.25rem;
        padding-top: 3rem;
      }
    }
  </style>
</head>
<body>
  <div id="site-nav-root"></div>
  <main class="page">
    <section class="section-header">
      <div class="section-badge">Robotics × LLM</div>
      <h1 class="section-title">Building a hierarchical VLM+RL manipulation system</h1>
      <p class="section-subtitle">
        Notes on building RoboLLM: a language-driven robotic manipulation system where a VLM decomposes
        instructions into sub-tasks and RL-trained policies execute each step in MuJoCo simulation.
      </p>
      <div class="post-meta">2025 · robotics · VLM · reinforcement learning · MuJoCo</div>
    </section>

    <section class="toc">
      <div class="toc-title">On this page</div>
      <ul>
        <li><a href="#motivation">Why hierarchical</a></li>
        <li><a href="#architecture">System architecture</a></li>
        <li><a href="#environment">MuJoCo environment design</a></li>
        <li><a href="#planner">VLM planner and grounding</a></li>
        <li><a href="#policies">RL policies and scripted baselines</a></li>
        <li><a href="#results">Benchmark results</a></li>
        <li><a href="#lessons">What I learned</a></li>
      </ul>
    </section>

    <section class="post-body">
      <p>
        Robotic manipulation is hard because it sits at the intersection of perception, planning, and precise motor
        control. End-to-end learning can handle simple tasks, but multi-step instructions like "stack the red block
        on the blue one, then move the green sphere to the left" require structured decomposition.
      </p>
      <p>
        RoboLLM implements the hierarchical approach from SayCan, RT-2, and Code-as-Policies: a vision-language model
        handles high-level task understanding, an object grounder maps descriptions to poses, and RL-trained motor
        policies execute each primitive. Scoped to run on a single T4 GPU.
      </p>

      <h2 id="motivation">Why hierarchical</h2>
      <p>
        The core insight is separation of concerns. Language understanding and task decomposition are
        fundamentally different problems from precise motor control:
      </p>
      <ul>
        <li><strong>Scripted planners</strong> are brittle — they can't handle novel instructions or paraphrases.</li>
        <li><strong>End-to-end RL</strong> is data-hungry and struggles with multi-step credit assignment.</li>
        <li><strong>Hierarchical</strong> lets each component do what it's best at: VLMs for language, RL for control.</li>
      </ul>
      <p>
        The practical benefit: you can swap the VLM (MockVLM for testing, PaliGemma-3B for production) without
        retraining motor policies, and vice versa. Clean interfaces between components.
      </p>

      <h2 id="architecture">System architecture</h2>
      <div class="mermaid-block">
        <div class="code-label">pipeline</div>
        <div class="mermaid">flowchart TB
  Instruction["Natural language instruction"] --> VLM["VLM Planner<br/><i>Decompose → sub-tasks</i>"]
  VLM --> Parser["Task Parser<br/><i>Validate + normalise</i>"]
  Parser --> Grounder["Object Grounder<br/><i>Text → object pose</i>"]
  Grounder --> Executor["Hierarchical Executor<br/><i>Per-subtask policies</i>"]
  Executor --> MuJoCo["MuJoCo Environment<br/><i>7-DoF arm + objects</i>"]
  MuJoCo --> Executor

  style VLM fill:#eff6ff,stroke:#2563eb,color:#0f172a
  style Grounder fill:#eff6ff,stroke:#2563eb,color:#0f172a
  style Executor fill:#eff6ff,stroke:#2563eb,color:#0f172a</div>
      </div>
      <p>
        The pipeline has five stages: (1) the VLM decomposes a natural language instruction into a JSON sequence of
        primitives, (2) the task parser validates ordering and normalises color/shape references, (3) the object grounder
        maps text descriptions to MuJoCo object poses, (4) the hierarchical executor runs the appropriate policy
        per sub-task, and (5) MuJoCo simulates the physics.
      </p>

      <h2 id="environment">MuJoCo environment design</h2>
      <p>
        The base environment models a Franka-inspired 7-DOF arm on a 60×60 cm tabletop. Key design choices:
      </p>
      <ul>
        <li><strong>Delta-EE control:</strong> Actions are 4D (delta x/y/z + gripper). Jacobian pseudoinverse with
          damping (λ=0.01) converts to joint velocities. This gives the RL agent a natural action space without
          needing to learn inverse kinematics.</li>
        <li><strong>Dynamic object spawning:</strong> Each reset generates new objects via XML injection — 3 shapes
          (box, cylinder, sphere) × 6 colors, with non-overlapping placement. The MuJoCo model is rebuilt every
          episode in ~5ms.</li>
        <li><strong>Task hierarchy:</strong> Five complexity levels from single pick-place (L1) to multi-step
          language instructions (L5). Each level adds new challenges: color selection, stacking order, zone
          sorting, condition checking.</li>
        <li><strong>200-step truncation:</strong> All episodes cap at 200 steps (10s sim time at 20Hz). Without this,
          random baselines run forever during evaluation.</li>
      </ul>

      <h2 id="planner">VLM planner and grounding</h2>
      <p>
        The planner uses an abstract VLM interface with two backends: MockVLM (deterministic keyword matching for
        testing) and TransformersVLM (HuggingFace models for real inference). The MockVLM achieves 100% accuracy
        on 20+ test scenarios — sufficient for pipeline integration testing without GPU.
      </p>
      <p>
        Object grounding maps text descriptions like "crimson cube" to actual object poses in the scene. The
        SimGrounder uses score-based matching: color match (+1.0), shape match (+0.5), name match (+0.2). It handles
        15+ color synonyms (crimson→red, azure→blue, jade→green) and 9 shape aliases (block/cube/brick→box).
      </p>
      <pre><code># Example pipeline execution
planner = Planner(MockVLM())
plan = planner.plan("pick up the red block and place it on the blue one")
# → TaskPlan: [move_to(red), pick(red), place(blue)]

grounder = SimGrounder()
result = grounder.ground("red block", scene_info)
# → GroundingResult(matched=obj_red_box, confidence=1.5)</code></pre>

      <h2 id="policies">RL policies and scripted baselines</h2>
      <p>
        Motor control uses SAC (Soft Actor-Critic) with automatic entropy tuning. The actor is a small MLP
        (obs→256→256→action) with squashed Gaussian output. Training runs at ~170 FPS on Apple Silicon (CPU-only).
      </p>
      <p>
        Scripted baselines provide comparison points:
      </p>
      <ul>
        <li><strong>ScriptedPickPlace:</strong> 8-phase state machine (approach → descend → grasp → lift → move →
          lower → release → done). Uses privileged info (exact object/goal positions).</li>
        <li><strong>ScriptedMoveTo:</strong> P-controller pointing EE toward the target object. Achieves 20% success
          rate — simple approach tasks are solvable with proportional control.</li>
      </ul>

      <h2 id="results">Benchmark results</h2>
      <p>
        100 episodes per task/policy pair, randomized initial placement, 200-step max:
      </p>
      <table>
        <thead>
          <tr><th>Task</th><th>Random</th><th>Scripted</th><th>Notes</th></tr>
        </thead>
        <tbody>
          <tr><td>L1 — Pick &amp; Place</td><td>0.0%</td><td>0.0%</td><td>Scripted gets 2.6× better returns</td></tr>
          <tr><td>L2 — Color Pick</td><td>0.0%</td><td>—</td><td>Multi-object color selection</td></tr>
          <tr><td>L3 — Stack</td><td>0.0%</td><td>—</td><td>Requires sequential precision</td></tr>
          <tr><td>L4 — Sort</td><td>0.0%</td><td>—</td><td>N objects → N zones</td></tr>
          <tr><td>L5 — Language</td><td>4.0%</td><td>—</td><td>Random meets some conditions by chance</td></tr>
          <tr><td>Move To</td><td>0.0%</td><td>20.0%</td><td>P-controller reaches targets</td></tr>
        </tbody>
      </table>
      <p>
        The honest take: multi-phase manipulation tasks (L1-L5) are hard. The scripted 8-phase state machine can't
        complete a full pick-and-place in 200 steps (0% SR), though it achieves 2.6× better returns than random.
        The MoveTo task is solvable with a simple P-controller (20% SR). Real success rates require trained RL
        policies with 500K+ environment steps or curriculum learning.
      </p>
      <p>
        The pipeline infrastructure works end-to-end: instruction → VLM decomposition → object grounding → policy
        execution → MuJoCo feedback. The bottleneck is motor skill, not planning.
      </p>

      <h2 id="lessons">What I learned</h2>
      <ul>
        <li><strong>Dataclass field names matter.</strong> The ObjectSpec uses <code>color_name</code> not
          <code>color</code>. A one-field mismatch caused 14 test failures across 3 modules. Always check the
          actual source, never assume.</li>
        <li><strong>Episode truncation is critical.</strong> Without a step limit, random agent evaluations run
          forever. Adding <code>max_episode_steps=200</code> to the base class fixed all downstream environments.</li>
        <li><strong>Mock backends unlock testing.</strong> MockVLM (keyword matching) + SimGrounder (privileged
          info) let the full pipeline be tested without GPU, model downloads, or non-determinism. 288 tests run
          in 17 seconds.</li>
        <li><strong>Honest benchmarks over impressive numbers.</strong> 0% pick-and-place success is real.
          The architecture is correct and tested — the motor skills need more training budget.</li>
        <li><strong>Jacobian pseudoinverse works well.</strong> Damped least squares (λ=0.01) handles singularities
          smoothly. Delta-EE control at 20Hz gives the RL agent a natural action space.</li>
      </ul>
      <p>
        The full codebase is at <a href="https://github.com/ajliouat/robollm" style="color: var(--accent);">github.com/ajliouat/robollm</a>
        — 288 tests, 10 releases from scaffold to stable, honest benchmark numbers from real evaluation runs.
      </p>
    </section>
  </main>
  <footer class="site-footer">
    <div class="site-footer-inner">
      <div class="site-footer-left">
        <span class="site-footer-brand">Abdeljalil Jliouat</span>
        <span>Building production AI systems across LLMs, robotics, quantum, and energy.</span>
      </div>
      <div class="site-footer-right">
        <span>Based in Paris · Available across Europe and remote</span>
        <a href="mailto:contact@ajliouat.com">contact@ajliouat.com</a>
      </div>
    </div>
  </footer>
  <script src="/nav.js"></script>
  <script src="/mermaid.js"></script>
</body>
</html>
